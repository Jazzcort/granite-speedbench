import { execSync } from "child_process";
import * as fs from "fs";
import os from "os";
import path from "path";

import {
  ConfigResult,
  ConfigValidationError,
  ModelRole,
} from "@continuedev/config-yaml";
import * as JSONC from "comment-json";
import * as tar from "tar";

import {
  BrowserSerializedContinueConfig,
  Config,
  ContextProviderWithParams,
  ContinueConfig,
  ContinueRcJson,
  CustomContextProvider,
  EmbeddingsProviderDescription,
  IContextProvider,
  IDE,
  IdeInfo,
  IdeSettings,
  IdeType,
  ILLM,
  ILLMLogger,
  LLMOptions,
  ModelDescription,
  RerankerDescription,
  SerializedContinueConfig,
  SlashCommand,
} from "..";
import {
  slashCommandFromDescription,
  slashFromCustomCommand,
} from "../commands/index";
import { MCPManagerSingleton } from "../context/mcp";
import CodebaseContextProvider from "../context/providers/CodebaseContextProvider";
import ContinueProxyContextProvider from "../context/providers/ContinueProxyContextProvider";
import CustomContextProviderClass from "../context/providers/CustomContextProvider";
import FileContextProvider from "../context/providers/FileContextProvider";
import { contextProviderClassFromName } from "../context/providers/index";
import { useHub } from "../control-plane/env";
import { BaseLLM } from "../llm";
import { LLMClasses, llmFromDescription } from "../llm/llms";
import CustomLLMClass from "../llm/llms/CustomLLM";
import FreeTrial from "../llm/llms/FreeTrial";
import { LLMReranker } from "../llm/llms/llm";
import TransformersJsEmbeddingsProvider from "../llm/llms/TransformersJsEmbeddingsProvider";
import { slashCommandFromPromptFileV1 } from "../promptFiles/v1/slashCommandFromPromptFile";
import { getAllPromptFiles } from "../promptFiles/v2/getPromptFiles";
import { allTools } from "../tools";
import { copyOf } from "../util";
import { GlobalContext } from "../util/GlobalContext";
import mergeJson from "../util/merge";
import {
  DEFAULT_CONFIG_TS_CONTENTS,
  getConfigJsonPath,
  getConfigJsonPathForRemote,
  getConfigJsPath,
  getConfigJsPathForRemote,
  getConfigTsPath,
  getContinueDotEnv,
  getEsbuildBinaryPath,
} from "../util/paths";
import { localPathToUri } from "../util/pathToUri";

import { modifyAnyConfigWithSharedConfig } from "./sharedConfig";
import {
  getModelByRole,
  isSupportedLanceDbCpuTargetForLinux,
  serializePromptTemplates,
} from "./util";
import { validateConfig } from "./validation.js";

export function resolveSerializedConfig(
  filepath: string,
): SerializedContinueConfig {
  let content = fs.readFileSync(filepath, "utf8");
  const config = JSONC.parse(content) as unknown as SerializedContinueConfig;
  if (config.env && Array.isArray(config.env)) {
    const env = {
      ...process.env,
      ...getContinueDotEnv(),
    };

    config.env.forEach((envVar) => {
      if (envVar in env) {
        content = (content as any).replaceAll(
          new RegExp(`"${envVar}"`, "g"),
          `"${env[envVar]}"`,
        );
      }
    });
  }

  return JSONC.parse(content) as unknown as SerializedContinueConfig;
}

const configMergeKeys = {
  models: (a: any, b: any) => a.title === b.title,
  contextProviders: (a: any, b: any) => a.name === b.name,
  slashCommands: (a: any, b: any) => a.name === b.name,
  customCommands: (a: any, b: any) => a.name === b.name,
};

function loadSerializedConfig(
  workspaceConfigs: ContinueRcJson[],
  ideSettings: IdeSettings,
  ideType: IdeType,
  overrideConfigJson: SerializedContinueConfig | undefined,
  ide: IDE,
): ConfigResult<SerializedContinueConfig> {
  let config: SerializedContinueConfig = overrideConfigJson!;
  if (!config) {
    try {
      config = resolveSerializedConfig(getConfigJsonPath());
    } catch (e) {
      throw new Error(`Failed to parse config.json: ${e}`);
    }
  }

  const errors = validateConfig(config);

  if (errors?.some((error) => error.fatal)) {
    return {
      errors,
      config: undefined,
      configLoadInterrupted: true,
    };
  }

  if (config.allowAnonymousTelemetry === undefined) {
    config.allowAnonymousTelemetry = true;
  }

  if (ideSettings.remoteConfigServerUrl) {
    try {
      const remoteConfigJson = resolveSerializedConfig(
        getConfigJsonPathForRemote(ideSettings.remoteConfigServerUrl),
      );
      config = mergeJson(config, remoteConfigJson, "merge", configMergeKeys);
    } catch (e) {
      console.warn("Error loading remote config: ", e);
    }
  }

  for (const workspaceConfig of workspaceConfigs) {
    config = mergeJson(
      config,
      workspaceConfig,
      workspaceConfig.mergeBehavior,
      configMergeKeys,
    );
  }

  if (os.platform() === "linux" && !isSupportedLanceDbCpuTargetForLinux(ide)) {
    config.disableIndexing = true;
  }

  return { config, errors, configLoadInterrupted: false };
}

async function serializedToIntermediateConfig(
  initial: SerializedContinueConfig,
  ide: IDE,
): Promise<Config> {
  // DEPRECATED - load custom slash commands
  const slashCommands: SlashCommand[] = [];
  for (const command of initial.slashCommands || []) {
    const newCommand = slashCommandFromDescription(command);
    if (newCommand) {
      slashCommands.push(newCommand);
    }
  }
  for (const command of initial.customCommands || []) {
    slashCommands.push(slashFromCustomCommand(command));
  }

  // DEPRECATED - load slash commands from v1 prompt files
  // NOTE: still checking the v1 default .prompts folder for slash commands
  const promptFiles = await getAllPromptFiles(
    ide,
    initial.experimental?.promptPath,
    true,
  );

  for (const file of promptFiles) {
    const slashCommand = slashCommandFromPromptFileV1(file.path, file.content);
    if (slashCommand) {
      slashCommands.push(slashCommand);
    }
  }

  const config: Config = {
    ...initial,
    slashCommands,
    contextProviders: initial.contextProviders || [],
  };

  return config;
}

export function isContextProviderWithParams(
  contextProvider: CustomContextProvider | ContextProviderWithParams,
): contextProvider is ContextProviderWithParams {
  return (contextProvider as ContextProviderWithParams).name !== undefined;
}

/** Only difference between intermediate and final configs is the `models` array */
async function intermediateToFinalConfig({
  config,
  ide,
  ideSettings,
  ideInfo,
  uniqueId,
  llmLogger,
  workOsAccessToken,
  loadPromptFiles = true,
  allowFreeTrial = true,
}: {
  config: Config;
  ide: IDE;
  ideSettings: IdeSettings;
  ideInfo: IdeInfo;
  uniqueId: string;
  llmLogger: ILLMLogger;
  workOsAccessToken: string | undefined;
  loadPromptFiles?: boolean;
  allowFreeTrial?: boolean;
}): Promise<{ config: ContinueConfig; errors: ConfigValidationError[] }> {
  const errors: ConfigValidationError[] = [];

  // Auto-detect models
  let models: BaseLLM[] = [];
  await Promise.all(
    config.models.map(async (desc) => {
      if ("title" in desc) {
        const llm = await llmFromDescription(
          desc,
          ide.readFile.bind(ide),
          uniqueId,
          ideSettings,
          llmLogger,
          config.completionOptions,
        );
        if (!llm) {
          return;
        }

        if (llm.model === "AUTODETECT") {
          try {
            const modelNames = await llm.listModels();
            const detectedModels = await Promise.all(
              modelNames.map(async (modelName) => {
                return await llmFromDescription(
                  {
                    ...desc,
                    model: modelName,
                    title: modelName,
                  },
                  ide.readFile.bind(ide),
                  uniqueId,
                  ideSettings,
                  llmLogger,
                  copyOf(config.completionOptions),
                );
              }),
            );
            models.push(
              ...(detectedModels.filter(
                (x) => typeof x !== "undefined",
              ) as BaseLLM[]),
            );
          } catch (e) {
            console.warn("Error listing models: ", e);
          }
        } else {
          models.push(llm);
        }
      } else {
        const llm = new CustomLLMClass({
          ...desc,
          options: { ...desc.options, logger: llmLogger } as any,
        });
        if (llm.model === "AUTODETECT") {
          try {
            const modelNames = await llm.listModels();
            const models = modelNames.map(
              (modelName) =>
                new CustomLLMClass({
                  ...desc,
                  options: {
                    ...desc.options,
                    model: modelName,
                    logger: llmLogger,
                  },
                }),
            );

            models.push(...models);
          } catch (e) {
            console.warn("Error listing models: ", e);
          }
        } else {
          models.push(llm);
        }
      }
    }),
  );

  // Prepare models
  for (const model of models) {
    model.requestOptions = {
      ...model.requestOptions,
      ...config.requestOptions,
    };
    model.roles = model.roles ?? ["chat", "apply", "edit", "summarize"]; // Default to chat role if not specified
  }

  if (allowFreeTrial) {
    // Obtain auth token (iff free trial being used)
    const freeTrialModels = models.filter(
      (model) => model.providerName === "free-trial",
    );
    if (freeTrialModels.length > 0) {
      const ghAuthToken = await ide.getGitHubAuthToken({});
      for (const model of freeTrialModels) {
        (model as FreeTrial).setupGhAuthToken(ghAuthToken);
      }
    }
  } else {
    // Remove free trial models
    models = models.filter((model) => model.providerName !== "free-trial");
  }

  // Tab autocomplete model
  let tabAutocompleteModels: BaseLLM[] = [];
  if (config.tabAutocompleteModel) {
    tabAutocompleteModels = (
      await Promise.all(
        (Array.isArray(config.tabAutocompleteModel)
          ? config.tabAutocompleteModel
          : [config.tabAutocompleteModel]
        ).map(async (desc) => {
          if ("title" in desc) {
            const llm = await llmFromDescription(
              desc,
              ide.readFile.bind(ide),
              uniqueId,
              ideSettings,
              llmLogger,
              config.completionOptions,
            );

            if (llm?.providerName === "free-trial") {
              if (!allowFreeTrial) {
                // This shouldn't happen
                throw new Error("Free trial cannot be used with control plane");
              }
              const ghAuthToken = await ide.getGitHubAuthToken({});
              (llm as FreeTrial).setupGhAuthToken(ghAuthToken);
            }
            return llm;
          } else {
            return new CustomLLMClass(desc);
          }
        }),
      )
    ).filter((x) => x !== undefined) as BaseLLM[];
  }

  // These context providers are always included, regardless of what, if anything,
  // the user has configured in config.json

  const codebaseContextParams =
    (
      (config.contextProviders || [])
        .filter(isContextProviderWithParams)
        .find((cp) => cp.name === "codebase") as
        | ContextProviderWithParams
        | undefined
    )?.params || {};

  const DEFAULT_CONTEXT_PROVIDERS = [
    new FileContextProvider({}),
    // Add codebase provider if indexing is enabled
    ...(!config.disableIndexing
      ? [new CodebaseContextProvider(codebaseContextParams)]
      : []),
  ];

  const DEFAULT_CONTEXT_PROVIDERS_TITLES = DEFAULT_CONTEXT_PROVIDERS.map(
    ({ description: { title } }) => title,
  );

  // Context providers
  const contextProviders: IContextProvider[] = DEFAULT_CONTEXT_PROVIDERS;

  for (const provider of config.contextProviders || []) {
    if (isContextProviderWithParams(provider)) {
      const cls = contextProviderClassFromName(provider.name) as any;
      if (!cls) {
        if (!DEFAULT_CONTEXT_PROVIDERS_TITLES.includes(provider.name)) {
          console.warn(`Unknown context provider ${provider.name}`);
        }

        continue;
      }
      const instance: IContextProvider = new cls(provider.params);

      // Handle continue-proxy
      if (instance.description.title === "continue-proxy") {
        (instance as ContinueProxyContextProvider).workOsAccessToken =
          workOsAccessToken;
      }

      contextProviders.push(instance);
    } else {
      contextProviders.push(new CustomContextProviderClass(provider));
    }
  }

  // Embeddings Provider
  function getEmbeddingsILLM(
    embedConfig: EmbeddingsProviderDescription | ILLM | undefined,
  ): ILLM | null {
    if (embedConfig) {
      // config.ts-injected ILLM
      if ("providerName" in embedConfig) {
        return embedConfig;
      }
      const { provider, ...options } = embedConfig;
      if (provider === "transformers.js") {
        return new TransformersJsEmbeddingsProvider();
      } else {
        const cls = LLMClasses.find((c) => c.providerName === provider);
        if (cls) {
          const llmOptions: LLMOptions = {
            model: options.model ?? "UNSPECIFIED",
            ...options,
          };
          return new cls(llmOptions);
        } else {
          errors.push({
            fatal: false,
            message: `Embeddings provider ${provider} not found`,
          });
        }
      }
    }
    if (ideInfo.ideType === "vscode") {
      return new TransformersJsEmbeddingsProvider();
    }
    return null;
  }
  const newEmbedder = getEmbeddingsILLM(config.embeddingsProvider);

  // Reranker
  function getRerankingILLM(
    rerankingConfig: ILLM | RerankerDescription | undefined,
  ): ILLM | null {
    if (!rerankingConfig) {
      return null;
    }
    // config.ts-injected ILLM
    if ("providerName" in rerankingConfig) {
      return rerankingConfig;
    }
    const { name, params } = config.reranker as RerankerDescription;

    if (name === "llm") {
      const llm = models.find((model) => model.title === params?.modelTitle);
      if (!llm) {
        errors.push({
          fatal: false,
          message: `Unknown reranking model ${params?.modelTitle}`,
        });
        return null;
      } else {
        return new LLMReranker(llm);
      }
    } else {
      const cls = LLMClasses.find((c) => c.providerName === name);
      if (cls) {
        const llmOptions: LLMOptions = {
          model: params?.model,
          ...params,
        };
        return new cls(llmOptions);
      } else {
        errors.push({
          fatal: false,
          message: `Unknown reranking provider ${name}`,
        });
      }
    }
    return null;
  }
  const newReranker = getRerankingILLM(config.reranker);

  const continueConfig: ContinueConfig = {
    ...config,
    contextProviders,
    tools: [...allTools],
    mcpServerStatuses: [],
    slashCommands: config.slashCommands ?? [],
    modelsByRole: {
      chat: models,
      edit: models,
      apply: models,
      summarize: models,
      autocomplete: [...tabAutocompleteModels],
      embed: newEmbedder ? [newEmbedder] : [],
      rerank: newReranker ? [newReranker] : [],
    },
    selectedModelByRole: {
      chat: null, // Not implemented (uses GUI defaultModel)
      edit: null,
      apply: null,
      embed: newEmbedder ?? null,
      autocomplete: null,
      rerank: newReranker ?? null,
      summarize: null, // Not implemented
    },
    rules: [],
  };

  if (config.systemMessage) {
    continueConfig.rules.unshift({
      rule: config.systemMessage,
      source: "json-systemMessage",
    });
  }

  // Trigger MCP server refreshes (Config is reloaded again once connected!)
  const mcpManager = MCPManagerSingleton.getInstance();
  mcpManager.setConnections(
    (config.experimental?.modelContextProtocolServers ?? []).map(
      (server, index) => ({
        id: `continue-mcp-server-${index + 1}`,
        name: `MCP Server`,
        ...server,
      }),
    ),
    false,
  );

  // Handle experimental modelRole config values for apply and edit
  const inlineEditModel = getModelByRole(continueConfig, "inlineEdit")?.title;
  if (inlineEditModel) {
    const match = continueConfig.modelsByRole.chat.find(
      (m) => m.title === inlineEditModel,
    );
    if (match) {
      continueConfig.selectedModelByRole.edit = match;
      continueConfig.modelsByRole.edit = [match]; // The only option if inlineEdit role is set
    } else {
      errors.push({
        fatal: false,
        message: `experimental.modelRoles.inlineEdit model title ${inlineEditModel} not found in models array`,
      });
    }
  }

  const applyBlockModel = getModelByRole(
    continueConfig,
    "applyCodeBlock",
  )?.title;
  if (applyBlockModel) {
    const match = continueConfig.modelsByRole.chat.find(
      (m) => m.title === applyBlockModel,
    );
    if (match) {
      continueConfig.selectedModelByRole.apply = match;
      continueConfig.modelsByRole.apply = [match]; // The only option if applyCodeBlock role is set
    } else {
      errors.push({
        fatal: false,
        message: `experimental.modelRoles.applyCodeBlock model title ${inlineEditModel} not found in models array`,
      });
    }
  }

  // Add transformers JS to the embed models list if not already added
  if (
    ideInfo.ideType === "vscode" &&
    !continueConfig.modelsByRole.embed.find(
      (m) => m.providerName === "transformers.js",
    )
  ) {
    continueConfig.modelsByRole.embed.push(
      new TransformersJsEmbeddingsProvider(),
    );
  }

  return { config: continueConfig, errors };
}

function llmToSerializedModelDescription(llm: ILLM): ModelDescription {
  return {
    provider: llm.providerName,
    model: llm.model,
    title: llm.title ?? llm.model,
    apiKey: llm.apiKey,
    apiBase: llm.apiBase,
    contextLength: llm.contextLength,
    template: llm.template,
    completionOptions: llm.completionOptions,
    baseChatSystemMessage: llm.baseChatSystemMessage,
    requestOptions: llm.requestOptions,
    promptTemplates: serializePromptTemplates(llm.promptTemplates),
    capabilities: llm.capabilities,
    roles: llm.roles,
    configurationStatus: llm.getConfigurationStatus(),
  };
}

async function finalToBrowserConfig(
  final: ContinueConfig,
  ide: IDE,
): Promise<BrowserSerializedContinueConfig> {
  return {
    allowAnonymousTelemetry: final.allowAnonymousTelemetry,
    completionOptions: final.completionOptions,
    slashCommands: final.slashCommands?.map(
      ({ run, ...slashCommandDescription }) => slashCommandDescription,
    ),
    contextProviders: final.contextProviders?.map((c) => c.description),
    disableIndexing: final.disableIndexing,
    disableSessionTitles: final.disableSessionTitles,
    userToken: final.userToken,
    ui: final.ui,
    experimental: final.experimental,
    rules: final.rules,
    docs: final.docs,
    tools: final.tools,
    mcpServerStatuses: final.mcpServerStatuses,
    tabAutocompleteOptions: final.tabAutocompleteOptions,
    usePlatform: await useHub(ide.getIdeSettings()),
    modelsByRole: Object.fromEntries(
      Object.entries(final.modelsByRole).map(([k, v]) => [
        k,
        v.map(llmToSerializedModelDescription),
      ]),
    ) as Record<ModelRole, ModelDescription[]>, // TODO better types here
    selectedModelByRole: Object.fromEntries(
      Object.entries(final.selectedModelByRole).map(([k, v]) => [
        k,
        v ? llmToSerializedModelDescription(v) : null,
      ]),
    ) as Record<ModelRole, ModelDescription | null>, // TODO better types here
    // data not included here because client doesn't need
  };
}

function escapeSpacesInPath(p: string): string {
  return p.replace(/ /g, "\\ ");
}

async function handleEsbuildInstallation(ide: IDE, ideType: IdeType) {
  // JetBrains is currently the only IDE that we've reached the plugin size limit and
  // therefore need to install esbuild manually to reduce the size
  if (ideType !== "jetbrains") {
    return;
  }

  const globalContext = new GlobalContext();
  if (globalContext.get("hasDismissedConfigTsNoticeJetBrains")) {
    return;
  }

  const esbuildPath = getEsbuildBinaryPath();

  if (fs.existsSync(esbuildPath)) {
    return;
  }

  console.debug("No esbuild binary detected");

  const shouldInstall = await promptEsbuildInstallation(ide);

  if (shouldInstall) {
    await downloadAndInstallEsbuild(ide);
  }
}

async function promptEsbuildInstallation(ide: IDE): Promise<boolean> {
  const installMsg = "Install esbuild";
  const dismissMsg = "Dismiss";

  const res = await ide.showToast(
    "warning",
    "You're using a custom 'config.ts' file, which requires 'esbuild' to be installed. Would you like to install it now?",
    dismissMsg,
    installMsg,
  );

  if (res === dismissMsg) {
    const globalContext = new GlobalContext();
    globalContext.update("hasDismissedConfigTsNoticeJetBrains", true);
    return false;
  }

  return res === installMsg;
}

/**
 * The download logic is adapted from here: https://esbuild.github.io/getting-started/#download-a-build
 */
async function downloadAndInstallEsbuild(ide: IDE) {
  const esbuildPath = getEsbuildBinaryPath();
  const tempDir = fs.mkdtempSync(path.join(os.tmpdir(), "esbuild-"));

  try {
    const target = `${os.platform()}-${os.arch()}`;
    const version = "0.19.11";
    const url = `https://registry.npmjs.org/@esbuild/${target}/-/${target}-${version}.tgz`;
    const tgzPath = path.join(tempDir, `esbuild-${version}.tgz`);

    console.debug(`Downloading esbuild from: ${url}`);
    execSync(`curl -fo "${tgzPath}" "${url}"`);

    console.debug(`Extracting tgz file to: ${tempDir}`);
    await tar.x({
      file: tgzPath,
      cwd: tempDir,
      strip: 2, // Remove the top two levels of directories
    });

    // Ensure the destination directory exists
    const destDir = path.dirname(esbuildPath);
    if (!fs.existsSync(destDir)) {
      fs.mkdirSync(destDir, { recursive: true });
    }

    // Move the file
    const extractedBinaryPath = path.join(tempDir, "esbuild");
    fs.renameSync(extractedBinaryPath, esbuildPath);

    // Ensure the binary is executable (not needed on Windows)
    if (os.platform() !== "win32") {
      fs.chmodSync(esbuildPath, 0o755);
    }

    // Clean up
    fs.unlinkSync(tgzPath);
    fs.rmSync(tempDir, { recursive: true });

    await ide.showToast(
      "info",
      `'esbuild' successfully installed to ${esbuildPath}`,
    );
  } catch (error) {
    console.error("Error downloading or saving esbuild binary:", error);
    throw error;
  }
}

async function tryBuildConfigTs() {
  try {
    if (process.env.IS_BINARY === "true") {
      await buildConfigTsWithBinary();
    } else {
      await buildConfigTsWithNodeModule();
    }
  } catch (e) {
    console.log(
      `Build error. Please check your ~/.continue/config.ts file: ${e}`,
    );
  }
}

async function buildConfigTsWithBinary() {
  const cmd = [
    escapeSpacesInPath(getEsbuildBinaryPath()),
    escapeSpacesInPath(getConfigTsPath()),
    "--bundle",
    `--outfile=${escapeSpacesInPath(getConfigJsPath())}`,
    "--platform=node",
    "--format=cjs",
    "--sourcemap",
    "--external:fetch",
    "--external:fs",
    "--external:path",
    "--external:os",
    "--external:child_process",
  ].join(" ");

  execSync(cmd);
}

async function buildConfigTsWithNodeModule() {
  const { build } = await import("esbuild");

  await build({
    entryPoints: [getConfigTsPath()],
    bundle: true,
    platform: "node",
    format: "cjs",
    outfile: getConfigJsPath(),
    external: ["fetch", "fs", "path", "os", "child_process"],
    sourcemap: true,
  });
}

function readConfigJs(): string | undefined {
  const configJsPath = getConfigJsPath();

  if (!fs.existsSync(configJsPath)) {
    return undefined;
  }

  return fs.readFileSync(configJsPath, "utf8");
}

async function buildConfigTsandReadConfigJs(ide: IDE, ideType: IdeType) {
  const configTsPath = getConfigTsPath();

  if (!fs.existsSync(configTsPath)) {
    return;
  }

  const currentContent = fs.readFileSync(configTsPath, "utf8");

  // If the user hasn't modified the default config.ts, don't bother building
  if (currentContent.trim() === DEFAULT_CONFIG_TS_CONTENTS.trim()) {
    return;
  }

  await handleEsbuildInstallation(ide, ideType);
  await tryBuildConfigTs();

  return readConfigJs();
}

async function loadContinueConfigFromJson(
  ide: IDE,
  workspaceConfigs: ContinueRcJson[],
  ideSettings: IdeSettings,
  ideInfo: IdeInfo,
  uniqueId: string,
  llmLogger: ILLMLogger,
  workOsAccessToken: string | undefined,
  overrideConfigJson: SerializedContinueConfig | undefined,
): Promise<ConfigResult<ContinueConfig>> {
  // Serialized config
  let {
    config: serialized,
    errors,
    configLoadInterrupted,
  } = loadSerializedConfig(
    workspaceConfigs,
    ideSettings,
    ideInfo.ideType,
    overrideConfigJson,
    ide,
  );

  if (!serialized || configLoadInterrupted) {
    return { errors, config: undefined, configLoadInterrupted: true };
  }

  // Apply shared config
  // TODO: override several of these values with user/org shared config
  const sharedConfig = new GlobalContext().getSharedConfig();
  const withShared = modifyAnyConfigWithSharedConfig(serialized, sharedConfig);

  // Convert serialized to intermediate config
  let intermediate = await serializedToIntermediateConfig(withShared, ide);

  // Apply config.ts to modify intermediate config
  const configJsContents = await buildConfigTsandReadConfigJs(
    ide,
    ideInfo.ideType,
  );
  if (configJsContents) {
    try {
      // Try config.ts first
      const configJsPath = getConfigJsPath();
      let module: any;

      try {
        module = await import(configJsPath);
      } catch (e) {
        console.log(e);
        console.log(
          "Could not load config.ts as absolute path, retrying as file url ...",
        );
        try {
          module = await import(localPathToUri(configJsPath));
        } catch (e) {
          throw new Error("Could not load config.ts as file url either", {
            cause: e,
          });
        }
      }

      if (typeof require !== "undefined") {
        delete require.cache[require.resolve(configJsPath)];
      }
      if (!module.modifyConfig) {
        throw new Error("config.ts does not export a modifyConfig function.");
      }
      intermediate = module.modifyConfig(intermediate);
    } catch (e) {
      console.log("Error loading config.ts: ", e);
    }
  }

  // Apply remote config.js to modify intermediate config
  if (ideSettings.remoteConfigServerUrl) {
    try {
      const configJsPathForRemote = getConfigJsPathForRemote(
        ideSettings.remoteConfigServerUrl,
      );
      const module = await import(configJsPathForRemote);
      if (typeof require !== "undefined") {
        delete require.cache[require.resolve(configJsPathForRemote)];
      }
      if (!module.modifyConfig) {
        throw new Error("config.ts does not export a modifyConfig function.");
      }
      intermediate = module.modifyConfig(intermediate);
    } catch (e) {
      console.log("Error loading remotely set config.js: ", e);
    }
  }

  // Convert to final config format
  const { config: finalConfig, errors: finalErrors } =
    await intermediateToFinalConfig({
      config: intermediate,
      ide,
      ideSettings,
      ideInfo,
      uniqueId,
      llmLogger,
      workOsAccessToken,
    });
  return {
    config: finalConfig,
    errors: [...(errors ?? []), ...finalErrors],
    configLoadInterrupted: false,
  };
}

export {
  finalToBrowserConfig,
  intermediateToFinalConfig,
  loadContinueConfigFromJson,
  type BrowserSerializedContinueConfig,
};

import fs from "fs";
import os from "os";

import { ModelConfig } from "@continuedev/config-yaml";
import {
  ContinueConfig,
  ExperimentalModelRoles,
  IDE,
  ILLM,
  JSONModelDescription,
  PromptTemplate,
} from "../";
import { DEFAULT_CHAT_SYSTEM_MESSAGE } from "../llm/constructMessages";
import { GlobalContext } from "../util/GlobalContext";
import { editConfigFile } from "../util/paths";

function stringify(obj: any, indentation?: number): string {
  return JSON.stringify(
    obj,
    (key, value) => {
      return value === null ? undefined : value;
    },
    indentation,
  );
}

export function addModel(
  model: JSONModelDescription,
  role?: keyof ExperimentalModelRoles,
) {
  editConfigFile(
    (config) => {
      if (config.models?.some((m) => stringify(m) === stringify(model))) {
        return config;
      }

      const numMatches = config.models?.reduce(
        (prev, curr) => (curr.title.startsWith(model.title) ? prev + 1 : prev),
        0,
      );
      if (numMatches !== 0) {
        model.title = `${model.title} (${numMatches})`;
      }

      config.models.push(model);

      // Set the role for the model
      if (role) {
        if (!config.experimental) {
          config.experimental = {};
        }
        if (!config.experimental.modelRoles) {
          config.experimental.modelRoles = {};
        }
        config.experimental.modelRoles[role] = model.title;
      }

      return config;
    },
    (config) => {
      const numMatches = config.models?.reduce(
        (prev, curr) =>
          "name" in curr && curr.name.startsWith(model.title) ? prev + 1 : prev,
        0,
      );
      if (numMatches !== 0) {
        model.title = `${model.title} (${numMatches})`;
      }

      if (!config.models) {
        config.models = [];
      }

      const desc: ModelConfig = {
        name: model.title,
        provider: model.provider,
        model: model.model,
        apiKey: model.apiKey,
        apiBase: model.apiBase,
        defaultCompletionOptions: model.completionOptions,
      };
      if (model.systemMessage) {
        desc.chatOptions = {
          baseSystemMessage:
            DEFAULT_CHAT_SYSTEM_MESSAGE + "\n\n" + model.systemMessage,
        };
      }
      config.models.push(desc);
      return config;
    },
  );
}

export function deleteModel(title: string) {
  editConfigFile(
    (config) => {
      config.models = config.models.filter((m: any) => m.title !== title);
      return config;
    },
    (config) => {
      config.models = config.models?.filter((m: any) => m.name !== title);
      return config;
    },
  );
}

export function getModelByRole<T extends keyof ExperimentalModelRoles>(
  config: ContinueConfig,
  role: T,
): ILLM | undefined {
  const roleTitle = config.experimental?.modelRoles?.[role];

  if (!roleTitle) {
    return undefined;
  }

  const matchingModel = config.modelsByRole.chat.find(
    (model) => model.title === roleTitle,
  );

  return matchingModel;
}

/**
 * This check is to determine if the user is on an unsupported CPU
 * target for our Lance DB binaries.
 *
 * See here for details: https://github.com/continuedev/continue/issues/940
 */
export function isSupportedLanceDbCpuTargetForLinux(ide?: IDE) {
  const CPU_FEATURES_TO_CHECK = ["avx2", "fma"] as const;

  const globalContext = new GlobalContext();
  const globalContextVal = globalContext.get(
    "isSupportedLanceDbCpuTargetForLinux",
  );

  // If we've already checked the CPU target, return the cached value
  if (globalContextVal !== undefined) {
    return globalContextVal;
  }

  const arch = os.arch();

  // This check only applies to x64
  //https://github.com/lancedb/lance/issues/2195#issuecomment-2057841311
  if (arch !== "x64") {
    globalContext.update("isSupportedLanceDbCpuTargetForLinux", true);
    return true;
  }

  try {
    const cpuFlags = fs.readFileSync("/proc/cpuinfo", "utf-8").toLowerCase();

    const isSupportedLanceDbCpuTargetForLinux = cpuFlags
      ? CPU_FEATURES_TO_CHECK.every((feature) => cpuFlags.includes(feature))
      : true;

    // If it's not a supported CPU target, and it's the first time we are checking,
    // show a toast to inform the user that we are going to disable indexing.
    if (!isSupportedLanceDbCpuTargetForLinux && ide) {
      // We offload our async toast to `showUnsupportedCpuToast` to prevent making
      // our config loading async upstream of `isSupportedLanceDbCpuTargetForLinux`
      void showUnsupportedCpuToast(ide);
    }

    globalContext.update(
      "isSupportedLanceDbCpuTargetForLinux",
      isSupportedLanceDbCpuTargetForLinux,
    );

    return isSupportedLanceDbCpuTargetForLinux;
  } catch (error) {
    // If we can't determine CPU features, default to true
    return true;
  }
}

async function showUnsupportedCpuToast(ide: IDE) {
  const shouldOpenLink = await ide.showToast(
    "warning",
    "Codebase indexing disabled - Your Linux system lacks required CPU features (AVX2, FMA)",
    "Learn more",
  );

  if (shouldOpenLink) {
    void ide.openUrl(
      "https://docs.continue.dev/troubleshooting#i-received-a-codebase-indexing-disabled---your-linux-system-lacks-required-cpu-features-avx2-fma-notification",
    );
  }
}

/**
 * This is required because users are only able to define prompt templates as a
 * string, while internally we also allow prompt templates to be functions
 * @param templates
 * @returns
 */
export function serializePromptTemplates(
  templates: Record<string, PromptTemplate> | undefined,
): Record<string, string> | undefined {
  if (!templates) return undefined;

  return Object.fromEntries(
    Object.entries(templates).map(([key, template]) => {
      const serialized = typeof template === "function" ? "" : template;
      return [key, serialized];
    }),
  );
}

/**
 * I'm disabling this rule for the entire file under the assumption
 * that this is a one-time migration script. I'm expecting this
 * code to be removed in the future.
 */
/* eslint-disable max-statements */

import { IDE } from "..";
import { deduplicateArray } from "../util";
import { GlobalContext } from "../util/GlobalContext";
import { resolveSerializedConfig } from "./load";
import { SharedConfigSchema } from "./sharedConfig";

/*
  This migration function eliminates deprecated values from the json file
  And writes them to the shared config
*/
export function migrateJsonSharedConfig(filepath: string, ide: IDE): void {
  const globalContext = new GlobalContext();
  const currentSharedConfig = globalContext.getSharedConfig(); // for merging security concerns

  try {
    let config = resolveSerializedConfig(filepath);
    const shareConfigUpdates: SharedConfigSchema = {};

    let effected = false;

    const { allowAnonymousTelemetry, ...withoutAllowTelemetry } = config;
    if (allowAnonymousTelemetry !== undefined) {
      if (currentSharedConfig.allowAnonymousTelemetry !== false) {
        // safe merge for security
        shareConfigUpdates.allowAnonymousTelemetry = allowAnonymousTelemetry;
      }
      config = withoutAllowTelemetry;
      effected = true;
    }

    const { disableIndexing, ...withoutDisableIndexing } = config;
    if (disableIndexing !== undefined) {
      if (currentSharedConfig.disableIndexing !== true) {
        // safe merge for security
        shareConfigUpdates.disableIndexing = disableIndexing;
      }
      config = withoutDisableIndexing;
      effected = true;
    }

    const { disableSessionTitles, ...withoutDisableSessionTitles } = config;
    if (config.disableSessionTitles !== undefined) {
      if (currentSharedConfig.disableSessionTitles !== true) {
        // safe merge for security
        shareConfigUpdates.disableSessionTitles = config.disableSessionTitles;
      }
      config = withoutDisableSessionTitles;
      effected = true;
    }

    const { tabAutocompleteOptions, ...withoutAutocompleteOptions } = config;
    if (tabAutocompleteOptions !== undefined) {
      let migratedAutocomplete = { ...tabAutocompleteOptions };

      const { useCache, ...withoutUseCache } = migratedAutocomplete;
      if (useCache !== undefined) {
        shareConfigUpdates.useAutocompleteCache = useCache;
        migratedAutocomplete = withoutUseCache;
        effected = true;
      }

      const { multilineCompletions, ...withoutMultiline } =
        migratedAutocomplete;
      if (multilineCompletions !== undefined) {
        shareConfigUpdates.useAutocompleteMultilineCompletions =
          multilineCompletions;
        migratedAutocomplete = withoutMultiline;
        effected = true;
      }

      const { disableInFiles, ...withoutDisableInFiles } = migratedAutocomplete;
      if (disableInFiles !== undefined) {
        if (currentSharedConfig.disableAutocompleteInFiles !== undefined) {
          // safe merge for security
          shareConfigUpdates.disableAutocompleteInFiles = deduplicateArray(
            [
              ...currentSharedConfig.disableAutocompleteInFiles,
              ...disableInFiles,
            ],
            (a, b) => a === b,
          );
        } else {
          shareConfigUpdates.disableAutocompleteInFiles = disableInFiles;
        }
        shareConfigUpdates.disableAutocompleteInFiles = disableInFiles;
        migratedAutocomplete = withoutDisableInFiles;
        effected = true;
      }

      if (Object.keys(migratedAutocomplete).length > 0) {
        config = {
          ...withoutAutocompleteOptions,
          tabAutocompleteOptions: migratedAutocomplete,
        };
      } else {
        config = withoutAutocompleteOptions;
      }
    }

    const { experimental, ...withoutExperimental } = config;
    if (experimental !== undefined) {
      let migratedExperimental = { ...experimental };

      const { useChromiumForDocsCrawling, ...rest10 } = migratedExperimental;
      if (useChromiumForDocsCrawling !== undefined) {
        shareConfigUpdates.useChromiumForDocsCrawling =
          useChromiumForDocsCrawling;
        migratedExperimental = rest10;
        effected = true;
      }

      const { promptPath, ...withoutPromptPath } = migratedExperimental;
      if (promptPath !== undefined) {
        shareConfigUpdates.promptPath = promptPath;
        migratedExperimental = withoutPromptPath;
        effected = true;
      }

      const { readResponseTTS, ...withoutReadTTS } = migratedExperimental;
      if (readResponseTTS !== undefined) {
        shareConfigUpdates.readResponseTTS = readResponseTTS;
        migratedExperimental = withoutReadTTS;
        effected = true;
      }

      if (Object.keys(migratedExperimental).length > 0) {
        config = {
          ...withoutExperimental,
          experimental: migratedExperimental,
        };
      } else {
        config = withoutExperimental;
      }
    }

    const { ui, ...withoutUI } = config;
    if (ui !== undefined) {
      let migratedUI = { ...ui };

      const { codeBlockToolbarPosition, ...withoutToolbarPosition } =
        migratedUI;
      if (codeBlockToolbarPosition !== undefined) {
        shareConfigUpdates.codeBlockToolbarPosition = codeBlockToolbarPosition;
        migratedUI = withoutToolbarPosition;
        effected = true;
      }

      const { fontSize, ...withoutFontSize } = migratedUI;
      if (fontSize !== undefined) {
        shareConfigUpdates.fontSize = fontSize;
        migratedUI = withoutFontSize;
        effected = true;
      }

      const { codeWrap, ...withoutCodeWrap } = migratedUI;
      if (codeWrap !== undefined) {
        shareConfigUpdates.codeWrap = codeWrap;
        migratedUI = withoutCodeWrap;
        effected = true;
      }

      const { displayRawMarkdown, ...withoutMD } = migratedUI;
      if (displayRawMarkdown !== undefined) {
        shareConfigUpdates.displayRawMarkdown = displayRawMarkdown;
        migratedUI = withoutMD;
        effected = true;
      }

      const { showChatScrollbar, ...withoutShowChatScrollbar } = migratedUI;
      if (showChatScrollbar !== undefined) {
        shareConfigUpdates.showChatScrollbar = showChatScrollbar;
        migratedUI = withoutShowChatScrollbar;
        effected = true;
      }

      // Ancient param to overwrite disableSessionTitles
      if ("getChatTitles" in migratedUI) {
        const { getChatTitles, ...withoutChatTitles } = migratedUI;
        if (getChatTitles === false) {
          shareConfigUpdates.disableSessionTitles = true;
          migratedUI = withoutChatTitles;
          effected = true;
        }
      }

      if (Object.keys(migratedUI).length > 0) {
        config = {
          ...withoutUI,
          ui: migratedUI,
        };
      } else {
        config = withoutUI;
      }
    }

    if (effected) {
      new GlobalContext().updateSharedConfig(shareConfigUpdates);
    }
  } catch (e) {
    throw new Error(`Migration: Failed to parse config.json: ${e}`);
  }
}

import fs from "node:fs";

import { ModelRole } from "@continuedev/config-yaml";

import { SiteIndexingConfig } from "..";
import {
  salvageSharedConfig,
  sharedConfigSchema,
  SharedConfigSchema,
} from "../config/sharedConfig";

import { getGlobalContextFilePath } from "./paths";

export type GlobalContextModelSelections = Partial<
  Record<ModelRole, string | null>
>;

export type GlobalContextType = {
  indexingPaused: boolean;
  lastSelectedProfileForWorkspace: {
    [workspaceIdentifier: string]: string | null;
  };
  lastSelectedOrgIdForWorkspace: {
    [workspaceIdentifier: string]: string | null;
  };
  selectedModelsByProfileId: {
    [profileId: string]: GlobalContextModelSelections;
  };

  /**
   * This is needed to handle the case where a JetBrains user has created
   * docs embeddings using one provider, and then updates to a new provider.
   *
   * For VS Code users, it is unnecessary since we use transformers.js by default.
   */
  hasDismissedConfigTsNoticeJetBrains: boolean;
  hasAlreadyCreatedAPromptFile: boolean;
  showConfigUpdateToast: boolean;
  isSupportedLanceDbCpuTargetForLinux: boolean;
  sharedConfig: SharedConfigSchema;
  failedDocs: SiteIndexingConfig[];
};

/**
 * A way to persist global state
 */
export class GlobalContext {
  update<T extends keyof GlobalContextType>(
    key: T,
    value: GlobalContextType[T],
  ) {
    const filepath = getGlobalContextFilePath();
    if (!fs.existsSync(filepath)) {
      fs.writeFileSync(
        filepath,
        JSON.stringify(
          {
            [key]: value,
          },
          null,
          2,
        ),
      );
    } else {
      const data = fs.readFileSync(filepath, "utf-8");

      let parsed;
      try {
        parsed = JSON.parse(data);
      } catch (e: any) {
        console.warn(`Error updating global context: ${e}`);
        return;
      }

      parsed[key] = value;
      fs.writeFileSync(filepath, JSON.stringify(parsed, null, 2));
    }
  }

  get<T extends keyof GlobalContextType>(
    key: T,
  ): GlobalContextType[T] | undefined {
    const filepath = getGlobalContextFilePath();
    if (!fs.existsSync(filepath)) {
      return undefined;
    }

    const data = fs.readFileSync(filepath, "utf-8");
    try {
      const parsed = JSON.parse(data);
      return parsed[key];
    } catch (e: any) {
      console.warn(`Error parsing global context: ${e}`);
      return undefined;
    }
  }

  getSharedConfig(): SharedConfigSchema {
    const sharedConfig = this.get("sharedConfig") ?? {};
    const result = sharedConfigSchema.safeParse(sharedConfig);
    if (result.success) {
      return result.data;
    } else {
      // in case of damaged shared config, repair it
      // Attempt to salvage any values that are security concerns
      console.error("Failed to load shared config, salvaging...", result.error);
      const salvagedConfig = salvageSharedConfig(sharedConfig);
      this.update("sharedConfig", salvagedConfig);
      return salvagedConfig;
    }
  }

  updateSharedConfig(
    newValues: Partial<SharedConfigSchema>,
  ): SharedConfigSchema {
    const currentSharedConfig = this.getSharedConfig();
    const updatedSharedConfig = {
      ...currentSharedConfig,
      ...newValues,
    };
    this.update("sharedConfig", updatedSharedConfig);
    return updatedSharedConfig;
  }

  updateSelectedModel(
    profileId: string,
    role: ModelRole,
    title: string | null,
  ): GlobalContextModelSelections {
    const currentSelections = this.get("selectedModelsByProfileId") ?? {};
    const forProfile = currentSelections[profileId] ?? {};
    const newSelections = {
      ...forProfile,
      [role]: title,
    };

    this.update("selectedModelsByProfileId", {
      ...currentSelections,
      [profileId]: newSelections,
    });
    return newSelections;
  }
}

import fs from "node:fs";

import {
  AssistantUnrolled,
  ConfigResult,
  ConfigValidationError,
  FQSN,
  isAssistantUnrolledNonNullable,
  MCPServer,
  ModelRole,
  PlatformClient,
  RegistryClient,
  Rule,
  SecretResult,
  unrollAssistantFromContent,
  validateConfigYaml,
} from "@continuedev/config-yaml";

import {
  ContinueConfig,
  ExperimentalMCPOptions,
  IContextProvider,
  IDE,
  IdeInfo,
  IdeSettings,
  ILLMLogger,
  RuleWithSource,
} from "../..";
import { slashFromCustomCommand } from "../../commands";
import { MCPManagerSingleton } from "../../context/mcp";
import CodebaseContextProvider from "../../context/providers/CodebaseContextProvider";
import DocsContextProvider from "../../context/providers/DocsContextProvider";
import FileContextProvider from "../../context/providers/FileContextProvider";
import { contextProviderClassFromName } from "../../context/providers/index";
import { ControlPlaneClient } from "../../control-plane/client";
import FreeTrial from "../../llm/llms/FreeTrial";
import TransformersJsEmbeddingsProvider from "../../llm/llms/TransformersJsEmbeddingsProvider";
import { slashCommandFromPromptFileV1 } from "../../promptFiles/v1/slashCommandFromPromptFile";
import { getAllPromptFiles } from "../../promptFiles/v2/getPromptFiles";
import { allTools } from "../../tools";
import { GlobalContext } from "../../util/GlobalContext";
import { getConfigYamlPath } from "../../util/paths";
import { PlatformConfigMetadata } from "../profile/PlatformProfileLoader";
import { modifyAnyConfigWithSharedConfig } from "../sharedConfig";

import { getControlPlaneEnvSync } from "../../control-plane/env";
import { llmsFromModelConfig } from "./models";

export class LocalPlatformClient implements PlatformClient {
  constructor(
    private orgScopeId: string | null,
    private readonly client: ControlPlaneClient,
  ) {}

  async resolveFQSNs(fqsns: FQSN[]): Promise<(SecretResult | undefined)[]> {
    if (fqsns.length === 0) {
      return [];
    }

    const response = await this.client.resolveFQSNs(fqsns, this.orgScopeId);
    return response;
  }
}

function convertYamlRuleToContinueRule(rule: Rule): RuleWithSource {
  if (typeof rule === "string") {
    return {
      rule: rule,
      source: "rules-block",
    };
  } else {
    return {
      source: "rules-block",
      rule: rule.rule,
      if: rule.if,
      name: rule.name,
    };
  }
}

function convertYamlMcpToContinueMcp(
  server: MCPServer,
): ExperimentalMCPOptions {
  return {
    transport: {
      type: "stdio",
      command: server.command,
      args: server.args ?? [],
      env: server.env,
    },
  };
}

async function loadConfigYaml(
  rawYaml: string,
  overrideConfigYaml: AssistantUnrolled | undefined,
  controlPlaneClient: ControlPlaneClient,
  orgScopeId: string | null,
  ideSettings: IdeSettings,
): Promise<ConfigResult<AssistantUnrolled>> {
  let config =
    overrideConfigYaml ??
    // This is how we allow use of blocks locally
    (await unrollAssistantFromContent(
      {
        ownerSlug: "",
        packageSlug: "",
        versionSlug: "",
      },
      rawYaml,
      new RegistryClient(
        await controlPlaneClient.getAccessToken(),
        getControlPlaneEnvSync(
          ideSettings.continueTestEnvironment,
          ideSettings.enableControlServerBeta,
        ).CONTROL_PLANE_URL,
      ),
      {
        currentUserSlug: "",
        onPremProxyUrl: null,
        orgScopeId,
        platformClient: new LocalPlatformClient(orgScopeId, controlPlaneClient),
        renderSecrets: true,
      },
    ));

  const errors = isAssistantUnrolledNonNullable(config)
    ? validateConfigYaml(config)
    : [
        {
          fatal: true,
          message: "Assistant includes blocks that don't exist",
        },
      ];

  if (errors?.some((error) => error.fatal)) {
    return {
      errors,
      config: undefined,
      configLoadInterrupted: true,
    };
  }

  // Set defaults if undefined (this lets us keep config.json uncluttered for new users)
  return {
    config,
    errors,
    configLoadInterrupted: false,
  };
}

async function configYamlToContinueConfig({
  config,
  ide,
  ideSettings,
  ideInfo,
  uniqueId,
  llmLogger,
  platformConfigMetadata,
  allowFreeTrial = true,
}: {
  config: AssistantUnrolled;
  ide: IDE;
  ideSettings: IdeSettings;
  ideInfo: IdeInfo;
  uniqueId: string;
  llmLogger: ILLMLogger;
  platformConfigMetadata: PlatformConfigMetadata | undefined;
  allowFreeTrial: boolean;
}): Promise<{ config: ContinueConfig; errors: ConfigValidationError[] }> {
  const localErrors: ConfigValidationError[] = [];

  const continueConfig: ContinueConfig = {
    slashCommands: [],
    tools: [...allTools],
    mcpServerStatuses: [],
    contextProviders: [],
    modelsByRole: {
      chat: [],
      edit: [],
      apply: [],
      embed: [],
      autocomplete: [],
      rerank: [],
      summarize: [],
    },
    selectedModelByRole: {
      chat: null,
      edit: null, // not currently used
      apply: null,
      embed: null,
      autocomplete: null,
      rerank: null,
      summarize: null,
    },
    rules: [],
  };

  // Right now, if there are any missing packages in the config, then we will just throw an error
  if (!isAssistantUnrolledNonNullable(config)) {
    return {
      config: continueConfig,
      errors: [
        {
          message: "Found missing blocks in config.yaml",
          fatal: true,
        },
      ],
    };
  }

  for (const rule of config.rules ?? []) {
    continueConfig.rules.push(convertYamlRuleToContinueRule(rule));
  }

  continueConfig.data = config.data;
  continueConfig.docs = config.docs?.map((doc) => ({
    title: doc.name,
    startUrl: doc.startUrl,
    rootUrl: doc.rootUrl,
    faviconUrl: doc.faviconUrl,
  }));
  continueConfig.experimental = {
    modelContextProtocolServers: config.mcpServers?.map(
      convertYamlMcpToContinueMcp,
    ),
  };

  // Prompt files -
  try {
    const promptFiles = await getAllPromptFiles(ide, undefined, true);

    promptFiles.forEach((file) => {
      try {
        const slashCommand = slashCommandFromPromptFileV1(
          file.path,
          file.content,
        );
        if (slashCommand) {
          continueConfig.slashCommands?.push(slashCommand);
        }
      } catch (e) {
        localErrors.push({
          fatal: false,
          message: `Failed to convert prompt file ${file.path} to slash command: ${e instanceof Error ? e.message : e}`,
        });
      }
    });
  } catch (e) {
    localErrors.push({
      fatal: false,
      message: `Error loading local prompt files: ${e instanceof Error ? e.message : e}`,
    });
  }

  config.prompts?.forEach((prompt) => {
    try {
      const slashCommand = slashFromCustomCommand(prompt);
      continueConfig.slashCommands?.push(slashCommand);
    } catch (e) {
      localErrors.push({
        message: `Error loading prompt ${prompt.name}: ${e instanceof Error ? e.message : e}`,
        fatal: false,
      });
    }
  });

  // Models
  const defaultModelRoles: ModelRole[] = ["chat", "summarize", "apply", "edit"];
  for (const model of config.models ?? []) {
    model.roles = model.roles ?? defaultModelRoles; // Default to all 4 chat-esque roles if not specified
    try {
      const llms = await llmsFromModelConfig({
        model,
        ide,
        uniqueId,
        ideSettings,
        llmLogger,
        platformConfigMetadata,
        config: continueConfig,
      });

      if (model.roles?.includes("chat")) {
        continueConfig.modelsByRole.chat.push(...llms);
      }

      if (model.roles?.includes("summarize")) {
        continueConfig.modelsByRole.summarize.push(...llms);
      }

      if (model.roles?.includes("apply")) {
        continueConfig.modelsByRole.apply.push(...llms);
      }

      if (model.roles?.includes("edit")) {
        continueConfig.modelsByRole.edit.push(...llms);
      }

      if (model.roles?.includes("autocomplete")) {
        continueConfig.modelsByRole.autocomplete.push(...llms);
      }

      if (model.roles?.includes("embed")) {
        const { provider } = model;
        if (provider === "transformers.js") {
          if (ideInfo.ideType === "vscode") {
            continueConfig.modelsByRole.embed.push(
              new TransformersJsEmbeddingsProvider(),
            );
          } else {
            localErrors.push({
              fatal: false,
              message: `Transformers.js embeddings provider not supported in this IDE.`,
            });
          }
        } else {
          continueConfig.modelsByRole.embed.push(...llms);
        }
      }

      if (model.roles?.includes("rerank")) {
        continueConfig.modelsByRole.rerank.push(...llms);
      }
    } catch (e) {
      localErrors.push({
        fatal: false,
        message: `Failed to load model:\nName: ${model.name}\nModel: ${model.model}\nProvider: ${model.provider}\n${e instanceof Error ? e.message : e}`,
      });
    }
  }

  // Add transformers js to the embed models in vs code if not already added
  if (
    ideInfo.ideType === "vscode" &&
    !continueConfig.modelsByRole.embed.find(
      (m) => m.providerName === "transformers.js",
    )
  ) {
    continueConfig.modelsByRole.embed.push(
      new TransformersJsEmbeddingsProvider(),
    );
  }

  if (allowFreeTrial) {
    // Obtain auth token (iff free trial being used)
    const freeTrialModels = continueConfig.modelsByRole.chat.filter(
      (model) => model.providerName === "free-trial",
    );
    if (freeTrialModels.length > 0) {
      try {
        const ghAuthToken = await ide.getGitHubAuthToken({});
        for (const model of freeTrialModels) {
          (model as FreeTrial).setupGhAuthToken(ghAuthToken);
        }
      } catch (e) {
        localErrors.push({
          fatal: false,
          message: `Failed to obtain GitHub auth token for free trial:\n${e instanceof Error ? e.message : e}`,
        });
        // Remove free trial models
        continueConfig.modelsByRole.chat =
          continueConfig.modelsByRole.chat.filter(
            (model) => model.providerName !== "free-trial",
          );
      }
    }
  } else {
    // Remove free trial models
    continueConfig.modelsByRole.chat = continueConfig.modelsByRole.chat.filter(
      (model) => model.providerName !== "free-trial",
    );
  }

  // Context providers
  const codebaseContextParams: IContextProvider[] =
    (config.context || []).find((cp) => cp.provider === "codebase")?.params ||
    {};
  const DEFAULT_CONTEXT_PROVIDERS = [
    new FileContextProvider({}),
    new CodebaseContextProvider(codebaseContextParams),
  ];

  const DEFAULT_CONTEXT_PROVIDERS_TITLES = DEFAULT_CONTEXT_PROVIDERS.map(
    ({ description: { title } }) => title,
  );

  continueConfig.contextProviders = (config.context
    ?.map((context) => {
      const cls = contextProviderClassFromName(context.provider) as any;
      if (!cls) {
        if (!DEFAULT_CONTEXT_PROVIDERS_TITLES.includes(context.provider)) {
          localErrors.push({
            fatal: false,
            message: `Unknown context provider ${context.provider}`,
          });
        }
        return undefined;
      }
      const instance: IContextProvider = new cls(context.params ?? {});
      return instance;
    })
    .filter((p) => !!p) ?? []) as IContextProvider[];
  continueConfig.contextProviders.push(...DEFAULT_CONTEXT_PROVIDERS);

  if (
    continueConfig.docs?.length &&
    !continueConfig.contextProviders?.some(
      (cp) => cp.description.title === "docs",
    )
  ) {
    continueConfig.contextProviders.push(new DocsContextProvider({}));
  }

  // Trigger MCP server refreshes (Config is reloaded again once connected!)
  const mcpManager = MCPManagerSingleton.getInstance();
  mcpManager.setConnections(
    (config.mcpServers ?? []).map((server) => ({
      id: server.name,
      name: server.name,
      transport: {
        type: "stdio",
        args: [],
        ...server,
      },
    })),
    false,
  );

  return { config: continueConfig, errors: localErrors };
}

export async function loadContinueConfigFromYaml({
  ide,
  ideSettings,
  ideInfo,
  uniqueId,
  llmLogger,
  overrideConfigYaml,
  platformConfigMetadata,
  controlPlaneClient,
  configYamlPath,
  orgScopeId,
}: {
  ide: IDE;
  ideSettings: IdeSettings;
  ideInfo: IdeInfo;
  uniqueId: string;
  llmLogger: ILLMLogger;
  overrideConfigYaml: AssistantUnrolled | undefined;
  platformConfigMetadata: PlatformConfigMetadata | undefined;
  controlPlaneClient: ControlPlaneClient;
  configYamlPath: string | undefined;
  orgScopeId: string | null;
}): Promise<ConfigResult<ContinueConfig>> {
  const rawYaml =
    overrideConfigYaml === undefined
      ? fs.readFileSync(
          configYamlPath ?? getConfigYamlPath(ideInfo.ideType),
          "utf-8",
        )
      : "";

  const configYamlResult = await loadConfigYaml(
    rawYaml,
    overrideConfigYaml,
    controlPlaneClient,
    orgScopeId,
    ideSettings,
  );

  if (!configYamlResult.config || configYamlResult.configLoadInterrupted) {
    return {
      errors: configYamlResult.errors,
      config: undefined,
      configLoadInterrupted: true,
    };
  }

  const { config: continueConfig, errors: localErrors } =
    await configYamlToContinueConfig({
      config: configYamlResult.config,
      ide,
      ideSettings,
      ideInfo,
      uniqueId,
      llmLogger,
      platformConfigMetadata,
      allowFreeTrial: true,
    });

  // Apply shared config
  // TODO: override several of these values with user/org shared config
  // Don't try catch this - has security implications and failure should be fatal
  const sharedConfig = new GlobalContext().getSharedConfig();
  const withShared = modifyAnyConfigWithSharedConfig(
    continueConfig,
    sharedConfig,
  );
  if (withShared.allowAnonymousTelemetry === undefined) {
    withShared.allowAnonymousTelemetry = true;
  }

  return {
    config: withShared,
    errors: [...(configYamlResult.errors ?? []), ...localErrors],
    configLoadInterrupted: false,
  };
}

import { Writable } from "stream";
import {
  AssistantChatMessage,
  ChatMessage,
  LLMInteractionCancel,
  LLMInteractionError,
  LLMInteractionItem,
  LLMInteractionStartChat,
  LLMInteractionStartComplete,
  LLMInteractionStartFim,
  LLMInteractionSuccess,
  ThinkingChatMessage,
  ToolCallDelta,
  UserChatMessage,
} from "..";
import { LLMLogger } from "./logger";

// Markers for different overlapping interactions.
const LOG_PREFIXES = [" ", "|", "&", "%", "#"];
// Wrap wide to avoid messing up code
const DEFAULT_WRAP_WIDTH = 100;

interface InteractionData {
  prefix: string;
  startItem: LLMInteractionItem;
  lastItem: LLMInteractionItem | null;
}

function formatTimestamp(timestamp: number) {
  const date = new Date(timestamp);

  const hours = date.getUTCHours().toString().padStart(2, "0");
  const minutes = date.getUTCMinutes().toString().padStart(2, "0");
  const seconds = date.getUTCSeconds();
  const milliseconds = date.getUTCMilliseconds();

  // Format seconds with one decimal place
  const secondsFormatted = `${seconds}.${Math.floor(milliseconds / 100)}`;

  return `${hours}:${minutes}:${secondsFormatted.padStart(4, "0")}`;
}

/**
 * A class that formats LLM log output as a human-readable stream.
 * The general appearance of the output is something like:
 *
 *  01:23:45.6 [Chat]
 *             Options: {
 *               "maxTokens": 1000,
 *             }
 *             Role: system
 *             | You are a helpful assistant.
 *             Role: user
 *             | Who are you?
 *        +0.2 Role: assistant
 *             | How can I help you today?
 *        +0.3 | I can tell you about the weather or the stock mark
 *        +0.4 . et. [THIS LINE IS WRAPPED]
 * |01:23:46.1 [Complete]
 * |           Options: {
 * |             "maxTokens": 1000,
 * |           }
 * |           Prefix:
 * |           | COMPLETE THIS
 *        +0.6 Success
 *             PromptTokens: 50
 *             GeneratedTokens: 30
 * |      +0.2 Result:
 * |           | COMPLETION
 *
 * The lines with | are a second interaction that starts while the
 * first one is still in progress; every interaction starts with
 * an absolute timestamp, and relative timestamps are included for
 * separately received results in the same interaction.
 */
export class LLMLogFormatter {
  // Current active interactions
  private interactions: Record<string, InteractionData> = {};
  private lastItem: LLMInteractionItem | null = null;
  // Item that started the current line; we use this to determine
  // if the next line needs a timestamp.
  private lastLineStartItem: LLMInteractionItem | null = null;
  private openLine: boolean = false;
  private openLineChars: number = 0;
  private lastFreedPrefix: string | null = null;

  /**
   * Creates a new LLMLogWriter.
   * @param logger - The LLMLogger instance to listen to for log items
   * @param output - Stream to write formatted output to
   * @param wrapWidth - Maximum width of a line before wrapping
   */
  constructor(
    private logger: LLMLogger,
    private output: Writable,
    private wrapWidth: number = DEFAULT_WRAP_WIDTH,
  ) {
    this.logger.onLogItem((item) => {
      this.logItem(item);
    });
  }

  private getInteractionData(item: LLMInteractionItem) {
    let interaction = this.interactions[item.interactionId];
    if (interaction !== undefined) {
      return interaction;
    }

    let usedPrefixes = Object.values(this.interactions).map(
      (interaction) => interaction.prefix,
    );

    // Select a prefix that is not currently in use, and is
    // also not the last retired prefix - but with the
    // exception that we can reuse the empty prefix " "
    // immediately - this isn't confusing.
    let i = 0;
    let prefix;
    while (true) {
      const candidate = i < LOG_PREFIXES.length ? LOG_PREFIXES[i] : `X`;
      if (
        !usedPrefixes.includes(candidate) &&
        (candidate === " " || candidate !== this.lastFreedPrefix)
      ) {
        prefix = candidate;
        break;
      }
      i++;
    }

    this.interactions[item.interactionId] = {
      prefix,
      startItem: item,
      lastItem: null,
    };

    return this.interactions[item.interactionId];
  }

  private formatTimestamp(
    interaction: InteractionData,
    item: LLMInteractionItem,
  ) {
    if (item !== this.lastLineStartItem) {
      if (item === interaction.startItem) {
        return formatTimestamp(item.timestamp);
      } else {
        const delta = (item.timestamp - interaction.startItem.timestamp) / 1000;
        return ("+" + delta.toFixed(1)).padStart(10, " ");
      }
    } else {
      return "          ";
    }
  }

  // the implementation behind logLines and logMessageText
  private logFragment(
    item: LLMInteractionItem,
    fragment: string,
    startAt: number,
    marker: string = "",
    joinBefore: boolean = false,
    joinAfter: boolean = false,
    wrap: boolean = false,
  ) {
    const interaction = this.getInteractionData(item);

    if (
      this.openLine &&
      (!joinBefore || item.interactionId !== this.lastItem?.interactionId)
    ) {
      this.openLine = false;
      this.openLineChars = 0;
      this.output.write("\n");
    }

    let continueAt = null;
    if (
      wrap &&
      fragment.length - startAt > this.wrapWidth - this.openLineChars
    ) {
      continueAt = startAt + this.wrapWidth - this.openLineChars;

      // Look for a better line-breaking point at whitespace
      const searchBackwardLimit = Math.max(startAt, continueAt - 20); // Don't look back too far
      for (let i = continueAt; i > searchBackwardLimit; i--) {
        if (/\s/.test(fragment.charAt(i))) {
          continueAt = i + 1; // Break after the whitespace
          break;
        }
      }

      // When there's whitespace immediately after the wrap width,
      // the above will result in breaking *after* that, so we exceed
      // the wrap width. The trimEnd() avoids that.
      fragment = fragment.substring(startAt, continueAt).trimEnd();
      joinAfter = false;
    } else if (startAt > 0) {
      fragment = fragment.substring(startAt);
    }

    if (!this.openLine || !this.openLine) {
      let timestamp = this.formatTimestamp(interaction, item);
      this.output.write(`${interaction.prefix}${timestamp} ${marker}`);
      this.lastLineStartItem = item;
    }

    this.output.write(fragment);
    this.openLine = joinAfter;
    this.lastItem = item;
    if (!this.openLine) {
      this.output.write("\n");
      this.openLineChars = 0;
    } else {
      this.openLineChars += fragment.length;
    }

    return continueAt;
  }

  // Use for everything but text content; a newline is
  // implicitly added at the end of content
  private logLines(
    item: LLMInteractionItem,
    content: string,
    marker: string = "",
  ) {
    for (const line of content.split("\n")) {
      this.logFragment(item, line, 0, marker);
    }
  }

  // This logs text context - as compared to logLines:
  //  - No newline is appended to the end of content
  //  - consecutive calls to logMessageText for the same interaction
  //    will join onto a single line
  //  - It will wrap text at the wrap width
  private logMessageText(item: LLMInteractionItem, content: string) {
    const lines = content.split("\n");
    for (let i = 0; i < lines.length; i++) {
      let startAt: number | null = 0;
      let marker = "| ";
      while (startAt !== null) {
        // When wrapping, the next start position is turned;
        // null means we've written everything
        startAt = this.logFragment(
          item,
          lines[i],
          startAt,
          marker,
          true,
          i === lines.length - 1,
          true,
        );
        marker = ". ";
      }
    }
  }

  private logToolcalls(item: LLMInteractionItem, toolsCalls: ToolCallDelta[]) {
    for (const toolCall of toolsCalls) {
      this.logLines(
        item,
        `Tool call: ${JSON.stringify(toolCall, undefined, 2)}`,
      );
    }
  }

  private logMessageContent(
    item: LLMInteractionItem,
    message: AssistantChatMessage | UserChatMessage | ThinkingChatMessage,
  ) {
    if (typeof message.content === "string") {
      this.logMessageText(item, message.content);
    } else {
      for (const part of message.content) {
        if (part.type === "text") {
          this.logMessageText(item, part.text);
        } else {
          this.logLines(item, `Image: ${part.imageUrl.url}`);
        }
      }
    }
  }

  private logMessage(
    item: LLMInteractionItem,
    message: ChatMessage,
    forceRole: boolean = false,
  ) {
    let showRole = true;
    if (
      !forceRole &&
      (message.role === "assistant" || message.role === "thinking")
    ) {
      const interaction = this.getInteractionData(item);
      const lastMessage =
        interaction.lastItem?.kind === "message"
          ? interaction.lastItem.message
          : null;
      if (message.role === lastMessage?.role) {
        showRole = false;
      }
    }

    if (showRole) {
      this.logLines(item, "Role: " + message.role);
    }

    switch (message.role) {
      case "assistant":
        if (message.toolCalls) {
          this.logToolcalls(item, message.toolCalls);
        }
        this.logMessageContent(item, message);
        break;
      case "thinking":
        if (message.toolCalls) {
          this.logToolcalls(item, message.toolCalls);
        }
        this.logMessageContent(item, message);
        if (message.redactedThinking) {
          this.logLines(item, `Redacted Thinking: ${message.redactedThinking}`);
        }
        if (message.signature) {
          this.logLines(item, `Signature: ${message.signature}`);
        }
        break;
      case "user":
        this.logMessageContent(item, message);
        break;
      case "system":
        this.logMessageText(item, message.content);
        break;
      case "tool":
        this.logLines(item, `Tool Call ID: ${message.toolCallId}`);
        this.logMessageText(item, message.content);
        break;
    }
  }

  private logTokens(
    item: LLMInteractionSuccess | LLMInteractionError | LLMInteractionCancel,
  ) {
    this.logLines(item, `Prompt Tokens: ${item.promptTokens}`);
    this.logLines(item, `Generated Tokens: ${item.generatedTokens}`);
    if (item.thinkingTokens > 0) {
      this.logLines(item, `Thinking Tokens: ${item.thinkingTokens}`);
    }
  }

  private logOptions(
    item:
      | LLMInteractionStartChat
      | LLMInteractionStartComplete
      | LLMInteractionStartFim,
  ) {
    this.logLines(
      item,
      "Options: " + JSON.stringify(item.options, undefined, 2),
    );
  }

  private logItem(item: LLMInteractionItem) {
    const interaction = this.getInteractionData(item);

    switch (item.kind) {
      case "startChat":
        this.logLines(item, "[Chat]");
        this.logOptions(item);
        let lastMessage = null;
        for (let message of item.messages) {
          this.logMessage(item, message, true);
        }
        break;
      case "startComplete":
        this.logLines(item, "[Complete]");
        this.logOptions(item);
        this.logLines(item, "Prompt:");
        this.logLines(item, item.prompt, "| ");
        break;
      case "startFim":
        this.logLines(item, "[Fim]");
        this.logOptions(item);
        this.logLines(item, "Prefix:");
        this.logLines(item, item.prefix, "| ");
        this.logLines(item, "Suffix:");
        this.logLines(item, item.suffix, "| ");
        break;
      case "chunk":
        if (interaction.lastItem?.kind !== "chunk") {
          this.logLines(item, "Result:");
        }
        this.logMessageText(item, item.chunk);
        break;
      case "message":
        this.logMessage(item, item.message);
        break;
      case "cancel":
        this.logLines(item, "Cancelled");
        this.logTokens(item);
        break;
      case "error":
        this.logLines(item, "Error");
        this.logTokens(item);
        break;
      case "success":
        this.logLines(item, "Success");
        this.logTokens(item);
        break;
    }

    if (
      item.kind === "cancel" ||
      item.kind === "error" ||
      item.kind === "success"
    ) {
      if (interaction.prefix !== " ") {
        this.lastFreedPrefix = interaction.prefix;
      }
      delete this.interactions[item.interactionId];
    } else {
      interaction.lastItem = item;
    }
  }
}

import {
  ILLMLogger,
  ILLMInteractionLog,
  LLMInteractionItem,
  LLMInteractionItemDetails,
} from "..";

type LLMLogItemFunction = (item: LLMInteractionItem) => void;

export class LLMLogger implements ILLMLogger {
  private nextId = 0;

  public createInteractionLog(): LLMInteractionLog {
    return new LLMInteractionLog(this, (this.nextId++).toString());
  }

  private logItemListeners: LLMLogItemFunction[] = [];

  onLogItem(listener: LLMLogItemFunction) {
    this.logItemListeners.push(listener);
  }

  public _logItem(item: LLMInteractionItem) {
    for (const listener of this.logItemListeners) {
      listener(item);
    }
  }
}

async function* toAsyncIterable(
  nodeReadable: NodeJS.ReadableStream,
): AsyncGenerator<Uint8Array> {
  for await (const chunk of nodeReadable) {
    // @ts-ignore
    yield chunk as Uint8Array;
  }
}

export async function* streamResponse(
  response: Response,
): AsyncGenerator<string> {
  if (response.status !== 200) {
    throw new Error(await response.text());
  }

  if (!response.body) {
    throw new Error("No response body returned.");
  }

  // Get the major version of Node.js
  const nodeMajorVersion = parseInt(process.versions.node.split(".")[0], 10);

  if (nodeMajorVersion >= 20) {
    // Use the new API for Node 20 and above
    const stream = (ReadableStream as any).from(response.body);
    for await (const chunk of stream.pipeThrough(
      new TextDecoderStream("utf-8"),
    )) {
      yield chunk;
    }
  } else {
    // Fallback for Node versions below 20
    // Streaming with this method doesn't work as version 20+ does
    const decoder = new TextDecoder("utf-8");
    const nodeStream = response.body as unknown as NodeJS.ReadableStream;
    for await (const chunk of toAsyncIterable(nodeStream)) {
      yield decoder.decode(chunk, { stream: true });
    }
  }
}

Can you find bugs in the code?
